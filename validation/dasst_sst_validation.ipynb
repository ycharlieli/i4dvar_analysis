{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27116e3b-1d68-4b2d-aeae-454bcaad5c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "from dask.distributed import Client\n",
    "import time\n",
    "import datetime as dt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import sys\n",
    "import gc\n",
    "import numpy as np\n",
    "sys.setrecursionlimit(100000)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import matplotlib.colors as colors\n",
    "from matplotlib import path\n",
    "import scipy.io as sio\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\n",
    "import cartopy.feature as cfeature\n",
    "import seaborn as sns\n",
    "import cmaps\n",
    "import seapy\n",
    "from scipy.spatial import KDTree\n",
    "import dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cddafa1d-7775-4670-90b8-333061209f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define your root paths\n",
    "myobsroot = '/Volumes/TO_1/roms4dvar_ecs/i4dvar_outputs/INSITU_OBS/'\n",
    "mynlroot = '/Volumes/WD_3/outputs_SCORRECTION/'\n",
    "mydasstroot =  '/Volumes/WD_3/roms4dvar_ecs/i4dvar_outputs/'\n",
    "#define your workspace \n",
    "nl_workspace = 'outputs_201205/'\n",
    "dasst_workspace = 'workspace_sstbgqc/'\n",
    "obs_workspace = ''\n",
    "obs_file='geopolar_sst_2012to14_offshore.nc'\n",
    "nl_files = \"ocean_ecs_his_00*.nc\"\n",
    "dasst_files = \"STORAGE/posterior/ocean_ecs_fwd_*.nc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e039e94b-430e-4cca-8a75-1c795478acd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duration to be validated: from 2012-05-01-12H to 2013-05-31-12H, total of 396 days.\n",
      "         target obs variable: 6\n",
      "         target model variable: temp\n"
     ]
    }
   ],
   "source": [
    "#define your target data duration\n",
    "\n",
    "start_date = '2012-05-01-12H'\n",
    "end_date = '2013-05-31-12H'\n",
    "\n",
    "start_datetime = dt.datetime.strptime(start_date,\"%Y-%m-%d-%HH\")\n",
    "end_datetime = dt.datetime.strptime(end_date,\"%Y-%m-%d-%HH\")\n",
    "data_len = (end_datetime-start_datetime).days+1 \n",
    "\n",
    "#define your target variable\n",
    "obs_var = 6\n",
    "# 2d situation\n",
    "# model_var = 'temp_sur' \n",
    "#3d situation\n",
    "model_var = 'temp'\n",
    "\n",
    "# setting chunk size\n",
    "x_chunk = int(262/2)\n",
    "y_chunk = int(362/2)\n",
    "z_chunk = 10\n",
    "\n",
    "print('''duration to be validated: from %s to %s, total of %i days.\n",
    "         target obs variable: %s\n",
    "         target model variable: %s'''\n",
    "      %(start_date,end_date,data_len,obs_var,model_var))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7a89e87-94bc-4361-9151-b4f9c1b7c9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading observation data\n",
    "Obs_ds = xr.open_dataset(myobsroot+obs_workspace+obs_file,\n",
    "                           engine='netcdf4',\n",
    "                           # chunks={'longitude':260,'latitude':210},\n",
    "                         \n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c6de62f-e0d7-4518-aa66-82ad1357756d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting cruise observation data with specific time range \n",
    "start_obstime = (start_datetime - dt.datetime(1970,1,1)).total_seconds()/3600/24\n",
    "end_obstime = (end_datetime - dt.datetime(1970,1,1)).total_seconds()/3600/24\n",
    "\n",
    "this_range = np.where( \n",
    "                                (Obs_ds.obs_time.data >= start_obstime) &\n",
    "                                (Obs_ds.obs_time.data <= end_obstime)  &\n",
    "                                (Obs_ds.obs_provenance == 355)&\n",
    "                                (Obs_ds.obs_type == obs_var)\n",
    "                        )\n",
    "\n",
    "\n",
    "Obs_ds = Obs_ds.isel(datum=this_range[0]).copy()\n",
    "timestamp = [ dt.timedelta(itime)+dt.datetime(1970,1,1) for itime in Obs_ds.obs_time.data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8d7a243-dae7-4752-ba07-929314ee677d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Obs_ds = Obs_ds.assign_coords(datum=timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e2c704e-ad55-4f5c-ac1e-e80d3dedfbb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading costing 4.857848 min\n"
     ]
    }
   ],
   "source": [
    "# loading forward sst\n",
    "start = time.time()\n",
    "nl_ds = xr.open_mfdataset(mynlroot+nl_workspace+nl_files,\n",
    "                                      engine='netcdf4',coords='minimal',\n",
    "                                      parallel=True,\n",
    "                                      # chunks={'eta_rho':y_chunk,'xi_rho':x_chunk,\n",
    "                                      #      's_rho':z_chunk, # only 3d needed\n",
    "                                      #      'eta_u':y_chunk,'xi_u':x_chunk,\\\n",
    "                                      #      'eta_v':y_chunk,'xi_v':x_chunk,\\\n",
    "                                      #      'eta_psi':y_chunk,'xi_psi':x_chunk,},\n",
    "                                       )#.chunk(dict(ocean_time=-1))\n",
    "end = time.time()\n",
    "print('loading costing %f min'%((end-start)/60))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "094924df-e0ca-4552-8c41-ee8e6dabd0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading costing 4.805167 min\n"
     ]
    }
   ],
   "source": [
    "# loading forward sst\n",
    "start = time.time()\n",
    "dasst_ds = xr.open_mfdataset(mydasstroot+dasst_workspace+dasst_files,\n",
    "                                      engine='netcdf4',coords='minimal',\n",
    "                                      parallel=True,\n",
    "                                      # chunks={'eta_rho':y_chunk,'xi_rho':x_chunk,\n",
    "                                      #      's_rho':z_chunk, # odassty 3d needed\n",
    "                                      #      'eta_u':y_chunk,'xi_u':x_chunk,\\\n",
    "                                      #      'eta_v':y_chunk,'xi_v':x_chunk,\\\n",
    "                                      #      'eta_psi':y_chunk,'xi_psi':x_chunk,},\n",
    "                                       )#.chunk(dict(ocean_time=-1))\n",
    "end = time.time()\n",
    "print('loading costing %f min'%((end-start)/60))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "22af07f6-9b95-4c9e-af76-4286bf65cc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting forward sst with specific time range \n",
    "# for forward there is no qck file ,so the model var has only 'temp'\n",
    "# further we only want the surface data, so the s_rho = -1\n",
    "nl_data = nl_ds[model_var].sel(ocean_time=slice(start_date,end_date)).isel(s_rho=-1)\n",
    "# always drop the initial time of posterior since there is a jump\n",
    "nl_data = nl_data.drop_duplicates(dim='ocean_time',keep='last')\n",
    "# fwd_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "894312d1-816b-4489-8f73-368e4174429b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting forward sst with specific time range \n",
    "# for forward there is no qck file ,so the model var has odassty 'temp'\n",
    "# further we odassty want the surface data, so the s_rho = -1\n",
    "dasst_data = dasst_ds[model_var].sel(ocean_time=slice(start_date,end_date)).isel(s_rho=-1)\n",
    "# always drop the initial time of posterior since there is a jump\n",
    "dasst_data = dasst_data.drop_duplicates(dim='ocean_time',keep='last')\n",
    "# fwd_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f607aca1-be31-4cf0-9dbc-ad0444b62289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating costing 15.943614 min\n"
     ]
    }
   ],
   "source": [
    "#calculate the daily mean \n",
    "start = time.time()\n",
    "nl_dailymean = dask.compute(nl_data.resample(ocean_time='1d').mean())\n",
    "# nl_dailymean = nl_dailymean.assign_coords({'ocean_time':Obs_modgrd.ocean_time.data})\n",
    "end = time.time()\n",
    "print('calculating costing %f min'%((end-start)/60))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "657c9b0a-a3aa-48ba-ae0e-b0e6c1e45267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating costing 34.578921 min\n"
     ]
    }
   ],
   "source": [
    "#calculate the daily mean \n",
    "start = time.time()\n",
    "dasst_dailymean = dask.compute(dasst_data.resample(ocean_time='1d').mean())\n",
    "# dasst_dailymean = dasst_dailymean.assign_coords({'ocean_time':Obs_modgrd.ocean_time.data})\n",
    "end = time.time()\n",
    "print('calculating costing %f min'%((end-start)/60))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1ba56cde-9cef-4721-acb1-e78af68a0b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_sst_color = sio.loadmat('/Volumes/TO_1/roms4dvar_ecs/i4dvar_outputs/'+\n",
    "                           'LYG_rainbow.mat')['rainbow']\n",
    "my_sst = LinearSegmentedColormap.from_list('sst',my_sst_color, N = 256)\n",
    "my_div_color = np.array(  [\n",
    "                 [0,0,123],\n",
    "                [9,32,154],\n",
    "                [22,58,179],\n",
    "                [34,84,204],\n",
    "                [47,109,230],\n",
    "                [63,135,247],\n",
    "                [95,160,248],\n",
    "                [137,186,249],\n",
    "                [182,213,251],\n",
    "                [228,240,254],\n",
    "                [255,255,255],\n",
    "                [250,224,224],\n",
    "                [242,164,162],\n",
    "                [237,117,113],\n",
    "                [235,76,67],\n",
    "                [233,52,37],\n",
    "                [212,45,31],\n",
    "                [188,39,26],\n",
    "                [164,33,21],\n",
    "                [140,26,17],\n",
    "                [117,20,12]\n",
    "                ])/255\n",
    "my_div = LinearSegmentedColormap.from_list('div',my_div_color, N = 256)\n",
    "my_reds = LinearSegmentedColormap.from_list('div',my_div_color[10:], N = 256)\n",
    "my_palette = sns.color_palette(my_div_color[5:-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b603a9e3-8c2f-448b-aeec-d9a66746a4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@dask.delayed\n",
    "def interpolate_data_roms(roms_data, obs_points):\n",
    "\n",
    "    from scipy.interpolate import griddata\n",
    "    # print(roms_data.ocean_time)\n",
    "    lons = roms_data.lon_rho.data.flatten()\n",
    "    lats = roms_data.lat_rho.data.flatten()\n",
    "    values = roms_data.values  # 假设roms_data是二维数组，对应于网格点\n",
    "\n",
    "    # 根据观测点的经纬度进行插值\n",
    "    interpolation = griddata(\n",
    "        (lons, lats),\n",
    "        values.flatten(),\n",
    "        (obs_points['obs_lon'], obs_points['obs_lat']),\n",
    "        method='linear'\n",
    "    )\n",
    "    \n",
    "    return interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "50a633ca-98b9-459b-bd6c-9ceeade4a781",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@dask.delayed\n",
    "def fill_missing(lon_target,lat_target,data):\n",
    "    target_kdtree = KDTree(np.c_[lon_target,lat_target])\n",
    "    distance, indices = target_kdtree.query(np.c_[data['obs_lon'],data['obs_lat']])\n",
    "    data_target = np.full_like(lon_target,np.nan)\n",
    "    for i in range(len(data['obs_lon'])):\n",
    "        idx=indices[i]\n",
    "        data_target[idx] = data['obs_value'][i]\n",
    "        \n",
    "    return data_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ea0ac6-1361-4d2e-97e1-145e453282aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48b4765-6a70-438c-9f37-7ae15b8931cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22127132-cf32-4705-9420-a3c8481f0281",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc0d918-9b07-4909-8a68-8552ed203297",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
